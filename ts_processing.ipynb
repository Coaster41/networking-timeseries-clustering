{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85df88c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Config\n",
    "CITY = \"chicago\"\n",
    "\n",
    "DIR = \"data/LENS-2023-11-CSV/LENS-2023-11-CSV/inside-out/active\"\n",
    "VALUE_COLUMN = \"rtt\"\n",
    "TIME_COLUMN = \"timestamp\"\n",
    "\n",
    "CLUSTER_CSV = \"data/2024-01-24/cluster_results.csv\"\n",
    "FREQ = \"10ms\"\n",
    "BLOCK_SECONDS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e60078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rtt</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>2024-01-24 00:00:12.000</td>\n",
       "      <td>396.884962</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>2024-01-24 00:00:12.010</td>\n",
       "      <td>400.207015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>2024-01-24 00:00:12.020</td>\n",
       "      <td>389.998357</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>2024-01-24 00:00:12.030</td>\n",
       "      <td>379.528565</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>2024-01-24 00:00:12.070</td>\n",
       "      <td>340.219383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6120245</th>\n",
       "      <td>2024-01-24 23:38:41.840</td>\n",
       "      <td>127.328116</td>\n",
       "      <td>5673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6120246</th>\n",
       "      <td>2024-01-24 23:38:41.850</td>\n",
       "      <td>143.254740</td>\n",
       "      <td>5673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6120247</th>\n",
       "      <td>2024-01-24 23:38:41.860</td>\n",
       "      <td>133.201958</td>\n",
       "      <td>5673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6120248</th>\n",
       "      <td>2024-01-24 23:38:41.870</td>\n",
       "      <td>124.388290</td>\n",
       "      <td>5673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6120249</th>\n",
       "      <td>2024-01-24 23:38:41.880</td>\n",
       "      <td>114.147220</td>\n",
       "      <td>5673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5536761 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      timestamp         rtt    id\n",
       "1070    2024-01-24 00:00:12.000  396.884962     0\n",
       "1071    2024-01-24 00:00:12.010  400.207015     0\n",
       "1072    2024-01-24 00:00:12.020  389.998357     0\n",
       "1073    2024-01-24 00:00:12.030  379.528565     0\n",
       "1074    2024-01-24 00:00:12.070  340.219383     0\n",
       "...                         ...         ...   ...\n",
       "6120245 2024-01-24 23:38:41.840  127.328116  5673\n",
       "6120246 2024-01-24 23:38:41.850  143.254740  5673\n",
       "6120247 2024-01-24 23:38:41.860  133.201958  5673\n",
       "6120248 2024-01-24 23:38:41.870  124.388290  5673\n",
       "6120249 2024-01-24 23:38:41.880  114.147220  5673\n",
       "\n",
       "[5536761 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1) Reuse your df_raw construction (adapted here for completeness, but keep yours)\n",
    "df_hours = []\n",
    "start_seconds = [12, 27, 42, 57]\n",
    "\n",
    "for folder in os.listdir(f\"{DIR}/{CITY}\"):\n",
    "    for hour in range(24):\n",
    "        # csv_file_name = f\"data/2024-01-24/irtt-10ms-1h-2024-01-24-{hour:0{2}d}-00-00.csv\"\n",
    "\n",
    "        csv_file_name = f\"{DIR}/{CITY}/{folder}/irtt-10ms-1h-2024-01-24-{hour:0{2}d}-00-00.csv\"\n",
    "        if not os.path.exists(csv_file_name):\n",
    "            continue\n",
    "        try:\n",
    "            df_hour = pd.read_csv(csv_file_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {csv_file_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Convert ns to datetime and round to 10ms bins\n",
    "        df_hour[TIME_COLUMN] = pd.to_datetime(df_hour[TIME_COLUMN], unit=\"ns\").dt.round(FREQ)\n",
    "        # Filter out non-positive RTT\n",
    "        df_hour = df_hour[df_hour[VALUE_COLUMN] > 0].copy()\n",
    "        # Keep only relevant columns to reduce memory\n",
    "        df_hour = df_hour[[TIME_COLUMN, VALUE_COLUMN]]\n",
    "        df_hours.append(df_hour)\n",
    "\n",
    "if not df_hours:\n",
    "    raise RuntimeError(\"No hourly CSVs loaded. Check paths.\")\n",
    "\n",
    "df_raw = pd.concat(df_hours, ignore_index=True)\n",
    "df_raw = df_raw.drop_duplicates(subset=[TIME_COLUMN]).sort_values(TIME_COLUMN)\n",
    "\n",
    "# Align to first starting second in [12, 27, 42, 57]\n",
    "start_time = df_raw.loc[df_raw[TIME_COLUMN].dt.second.isin(start_seconds), TIME_COLUMN].min()\n",
    "if pd.isna(start_time):\n",
    "    raise RuntimeError(\"Could not find a start_time matching seconds in [12, 27, 42, 57].\")\n",
    "\n",
    "df_raw = df_raw.loc[df_raw[TIME_COLUMN] >= start_time].copy()\n",
    "\n",
    "# Compute 15s block id and filter last, too-short blocks\n",
    "df_raw[\"id\"] = ((df_raw[TIME_COLUMN] - start_time).dt.total_seconds() // BLOCK_SECONDS).astype(int)\n",
    "df_raw = df_raw.loc[df_raw[\"id\"] != df_raw[\"id\"].max()].copy()\n",
    "# Optional: keep only substantially populated blocks (your original threshold)\n",
    "df_raw = df_raw.groupby('id').filter(lambda x: len(x) > 1300).copy()\n",
    "display(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed0cdb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Load cluster labels; only process ids that exist in this file\n",
    "clusters = pd.read_csv(CLUSTER_CSV)\n",
    "# Ensure timestamp is parsed (optional but useful)\n",
    "if \"timestamp\" in clusters.columns:\n",
    "    clusters[\"timestamp\"] = pd.to_datetime(clusters[\"timestamp\"])\n",
    "# Keep only fields we need\n",
    "clusters = clusters[[\"id\", \"cluster\"]].drop_duplicates()\n",
    "\n",
    "# Restrict df_raw to ids present in clusters\n",
    "df_raw = df_raw[df_raw[\"id\"].isin(clusters[\"id\"])].copy()\n",
    "\n",
    "# 3) Helper: build canonical index for a given block id\n",
    "def expected_index_for_id(id_val: int) -> pd.DatetimeIndex:\n",
    "    start = start_time + pd.Timedelta(seconds=BLOCK_SECONDS * id_val)\n",
    "    # Inclusive end at 15s - one step (so 1500 points for 10ms frequency)\n",
    "    end = start + pd.Timedelta(seconds=BLOCK_SECONDS) - pd.Timedelta(milliseconds=10)\n",
    "    return pd.date_range(start, end, freq=FREQ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aefae69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Helper: nearest-neighbor imputation choosing last/next by closest distance\n",
    "def nearest_neighbor_fill_uniform(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    s is a Series indexed by a uniformly spaced DatetimeIndex (10ms).\n",
    "    Missing values are NaN.\n",
    "    We choose the nearest observed sample (prev or next). Ties: prefer previous.\n",
    "    \"\"\"\n",
    "    n = len(s)\n",
    "    mask = s.isna().values\n",
    "    if not mask.any():\n",
    "        return s\n",
    "\n",
    "    pos = np.arange(n)\n",
    "\n",
    "    # Indices of last observed sample at or before each position\n",
    "    prev_obs_pos = np.where(~mask, pos, np.nan)\n",
    "    prev_obs_pos = pd.Series(prev_obs_pos).ffill().values  # positions or NaN at leading missing\n",
    "\n",
    "    # Indices of next observed sample at or after each position\n",
    "    next_obs_pos = np.where(~mask, pos, np.nan)\n",
    "    next_obs_pos = pd.Series(next_obs_pos).bfill().values  # positions or NaN at trailing missing\n",
    "\n",
    "    # Distances\n",
    "    # Use large numbers where no prev/next exists\n",
    "    dist_prev = pos - prev_obs_pos\n",
    "    dist_prev = np.where(np.isnan(dist_prev), np.inf, dist_prev)\n",
    "    dist_next = next_obs_pos - pos\n",
    "    dist_next = np.where(np.isnan(dist_next), np.inf, dist_next)\n",
    "\n",
    "    # Choose prev if strictly closer or tie (<=), else next\n",
    "    use_prev = dist_prev <= dist_next\n",
    "\n",
    "    s_ffill = s.ffill()\n",
    "    s_bfill = s.bfill()\n",
    "\n",
    "    filled_values = np.where(use_prev, s_ffill.values, s_bfill.values)\n",
    "\n",
    "    out = s.copy()\n",
    "    out[mask] = filled_values[mask]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a605e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cluster</th>\n",
       "      <th>samples_expected</th>\n",
       "      <th>samples_observed</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_ratio</th>\n",
       "      <th>rtt_mean</th>\n",
       "      <th>rtt_std</th>\n",
       "      <th>rtt_median</th>\n",
       "      <th>rtt_p10</th>\n",
       "      <th>rtt_p90</th>\n",
       "      <th>nearest_fill_delta_mean</th>\n",
       "      <th>nearest_fill_delta_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>3408</td>\n",
       "      <td>2</td>\n",
       "      <td>1500</td>\n",
       "      <td>1302</td>\n",
       "      <td>198</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>211.304389</td>\n",
       "      <td>62.724034</td>\n",
       "      <td>242.718247</td>\n",
       "      <td>120.034292</td>\n",
       "      <td>262.741334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2173</th>\n",
       "      <td>3652</td>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "      <td>1303</td>\n",
       "      <td>197</td>\n",
       "      <td>0.131333</td>\n",
       "      <td>195.410981</td>\n",
       "      <td>47.873257</td>\n",
       "      <td>185.598667</td>\n",
       "      <td>166.603514</td>\n",
       "      <td>222.911011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>2918</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>1303</td>\n",
       "      <td>197</td>\n",
       "      <td>0.131333</td>\n",
       "      <td>111.746540</td>\n",
       "      <td>18.319269</td>\n",
       "      <td>108.083478</td>\n",
       "      <td>98.014673</td>\n",
       "      <td>126.703893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>3172</td>\n",
       "      <td>3</td>\n",
       "      <td>1500</td>\n",
       "      <td>1305</td>\n",
       "      <td>195</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>157.156896</td>\n",
       "      <td>6.409719</td>\n",
       "      <td>156.298391</td>\n",
       "      <td>151.707951</td>\n",
       "      <td>162.004716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>2888</td>\n",
       "      <td>6</td>\n",
       "      <td>1500</td>\n",
       "      <td>1305</td>\n",
       "      <td>195</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>133.726868</td>\n",
       "      <td>15.817170</td>\n",
       "      <td>129.715732</td>\n",
       "      <td>120.306890</td>\n",
       "      <td>150.173300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>2859</td>\n",
       "      <td>5</td>\n",
       "      <td>1500</td>\n",
       "      <td>1305</td>\n",
       "      <td>195</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>107.852606</td>\n",
       "      <td>20.668037</td>\n",
       "      <td>104.056336</td>\n",
       "      <td>93.449438</td>\n",
       "      <td>122.540518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>3699</td>\n",
       "      <td>2</td>\n",
       "      <td>1500</td>\n",
       "      <td>1306</td>\n",
       "      <td>194</td>\n",
       "      <td>0.129333</td>\n",
       "      <td>219.303079</td>\n",
       "      <td>65.124284</td>\n",
       "      <td>189.429763</td>\n",
       "      <td>163.297454</td>\n",
       "      <td>343.920526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>2855</td>\n",
       "      <td>2</td>\n",
       "      <td>1500</td>\n",
       "      <td>1307</td>\n",
       "      <td>193</td>\n",
       "      <td>0.128667</td>\n",
       "      <td>273.464655</td>\n",
       "      <td>19.415389</td>\n",
       "      <td>271.621304</td>\n",
       "      <td>253.938686</td>\n",
       "      <td>293.811632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2866</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>1309</td>\n",
       "      <td>191</td>\n",
       "      <td>0.127333</td>\n",
       "      <td>119.395677</td>\n",
       "      <td>14.750677</td>\n",
       "      <td>116.576421</td>\n",
       "      <td>105.388600</td>\n",
       "      <td>135.346662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2871</td>\n",
       "      <td>6</td>\n",
       "      <td>1500</td>\n",
       "      <td>1309</td>\n",
       "      <td>191</td>\n",
       "      <td>0.127333</td>\n",
       "      <td>129.260875</td>\n",
       "      <td>17.595357</td>\n",
       "      <td>125.414879</td>\n",
       "      <td>112.518733</td>\n",
       "      <td>148.239144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  cluster  samples_expected  samples_observed  missing_count  \\\n",
       "1931  3408        2              1500              1302            198   \n",
       "2173  3652        1              1500              1303            197   \n",
       "1470  2918        0              1500              1303            197   \n",
       "1708  3172        3              1500              1305            195   \n",
       "1461  2888        6              1500              1305            195   \n",
       "1452  2859        5              1500              1305            195   \n",
       "2214  3699        2              1500              1306            194   \n",
       "1449  2855        2              1500              1307            193   \n",
       "1454  2866        0              1500              1309            191   \n",
       "1457  2871        6              1500              1309            191   \n",
       "\n",
       "      missing_ratio    rtt_mean    rtt_std  rtt_median     rtt_p10  \\\n",
       "1931       0.132000  211.304389  62.724034  242.718247  120.034292   \n",
       "2173       0.131333  195.410981  47.873257  185.598667  166.603514   \n",
       "1470       0.131333  111.746540  18.319269  108.083478   98.014673   \n",
       "1708       0.130000  157.156896   6.409719  156.298391  151.707951   \n",
       "1461       0.130000  133.726868  15.817170  129.715732  120.306890   \n",
       "1452       0.130000  107.852606  20.668037  104.056336   93.449438   \n",
       "2214       0.129333  219.303079  65.124284  189.429763  163.297454   \n",
       "1449       0.128667  273.464655  19.415389  271.621304  253.938686   \n",
       "1454       0.127333  119.395677  14.750677  116.576421  105.388600   \n",
       "1457       0.127333  129.260875  17.595357  125.414879  112.518733   \n",
       "\n",
       "         rtt_p90  nearest_fill_delta_mean  nearest_fill_delta_max  \n",
       "1931  262.741334                      0.0                     0.0  \n",
       "2173  222.911011                      0.0                     0.0  \n",
       "1470  126.703893                      0.0                     0.0  \n",
       "1708  162.004716                      0.0                     0.0  \n",
       "1461  150.173300                      0.0                     0.0  \n",
       "1452  122.540518                      0.0                     0.0  \n",
       "2214  343.920526                      0.0                     0.0  \n",
       "1449  293.811632                      0.0                     0.0  \n",
       "1454  135.346662                      0.0                     0.0  \n",
       "1457  148.239144                      0.0                     0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5) Process each id into aligned sequences (long format)\n",
    "records = []\n",
    "feature_rows = []\n",
    "\n",
    "grouped = df_raw.groupby(\"id\", sort=True)\n",
    "for id_val, grp in grouped:\n",
    "    # Compute canonical index\n",
    "    idx = expected_index_for_id(id_val)\n",
    "\n",
    "    # Align this group's RTT to the canonical timeline\n",
    "    s = grp.set_index(TIME_COLUMN)[VALUE_COLUMN].sort_index()\n",
    "    s = s.reindex(idx)  # Missing samples become NaN\n",
    "    # Token with -1 for missing\n",
    "    s_token = s.fillna(-1)\n",
    "\n",
    "    # Nearest neighbor fill (last or next whichever is closer; ties -> last)\n",
    "    s_nearest = nearest_neighbor_fill_uniform(s)\n",
    "\n",
    "    # Missing mask (based on original aligned series)\n",
    "    missing_mask = s.isna()\n",
    "\n",
    "    # Cluster label\n",
    "    cluster = clusters.loc[clusters[\"id\"] == id_val, \"cluster\"]\n",
    "    cluster = int(cluster.iloc[0]) if len(cluster) else None\n",
    "\n",
    "    # Build long-form rows\n",
    "    df_block = pd.DataFrame({\n",
    "        \"id\": id_val,\n",
    "        \"timestamp\": idx,\n",
    "        \"rtt\": s.values,\n",
    "        \"rtt_token\": s_token.values,      # -1 indicates missing\n",
    "        \"rtt_nearest\": s_nearest.values,  # nearest neighbor imputation\n",
    "        \"is_missing\": missing_mask.values\n",
    "    })\n",
    "\n",
    "    # Append cluster if present\n",
    "    df_block[\"cluster\"] = cluster\n",
    "\n",
    "    records.append(df_block)\n",
    "\n",
    "    # Compute simple per-block features (good for training/eval)\n",
    "    # Feel free to expand with more robust statistics\n",
    "    valid = ~missing_mask\n",
    "    valid_vals = s[valid]\n",
    "    features = {\n",
    "        \"id\": id_val,\n",
    "        \"cluster\": cluster,\n",
    "        \"samples_expected\": len(s),\n",
    "        \"samples_observed\": int(valid.sum()),\n",
    "        \"missing_count\": int(missing_mask.sum()),\n",
    "        \"missing_ratio\": float(missing_mask.mean()),\n",
    "        \"rtt_mean\": float(valid_vals.mean()) if len(valid_vals) else np.nan,\n",
    "        \"rtt_std\": float(valid_vals.std(ddof=1)) if len(valid_vals) > 1 else np.nan,\n",
    "        \"rtt_median\": float(valid_vals.median()) if len(valid_vals) else np.nan,\n",
    "        \"rtt_p10\": float(valid_vals.quantile(0.10)) if len(valid_vals) else np.nan,\n",
    "        \"rtt_p90\": float(valid_vals.quantile(0.90)) if len(valid_vals) else np.nan,\n",
    "        # Compare imputation behavior\n",
    "        \"nearest_fill_delta_mean\": float((s_nearest - s).abs().mean(skipna=True)),\n",
    "        \"nearest_fill_delta_max\": float((s_nearest - s).abs().max(skipna=True)),\n",
    "    }\n",
    "    feature_rows.append(features)\n",
    "\n",
    "# Concatenate and save\n",
    "df_long = pd.concat(records, ignore_index=True)\n",
    "df_features = pd.DataFrame(feature_rows)\n",
    "\n",
    "# Optionally, inspect a couple of blocks\n",
    "display(df_features.sort_values(\"missing_ratio\", ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71526c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long_clean = df_long[[\"id\", \"timestamp\", \"rtt_token\", \"rtt_nearest\"]]\n",
    "df_long_clean.head()\n",
    "df_long_clean.to_csv('data/2024-01-24/clustering_data.csv', float_format='%.4f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1621cae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
